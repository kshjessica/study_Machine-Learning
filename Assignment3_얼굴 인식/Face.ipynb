{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "\n",
    "def create_dataset_train(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "    \n",
    "    for file in os.listdir(img_folder):\n",
    "        \n",
    "        image_path = os.path.join(img_folder, file)\n",
    "        image = load_img(image_path, 'rb')\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        if image.shape[2] == 3:\n",
    "            image = image.mean(2)\n",
    "        img_data_array.append(image)\n",
    "        name_index = file.split(\"_\")\n",
    "        name_index = int(name_index[0])\n",
    "        class_name.append(name_index)\n",
    "        \n",
    "    return np.array(img_data_array), np.array(class_name)\n",
    "\n",
    "def create_dataset_test(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "    \n",
    "    for file in os.listdir(img_folder):\n",
    "        \n",
    "        image_path = os.path.join(img_folder, file)\n",
    "        image = load_img(image_path, 'rb')\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        if image.shape[2] == 3:\n",
    "            image = image.mean(2)\n",
    "        img_data_array.append(image)\n",
    "        name_index = file.split(\".\")\n",
    "        name_index = int(name_index[0])\n",
    "        class_name.append(name_index)\n",
    "        \n",
    "    return np.array(img_data_array), np.array(class_name)\n",
    "\n",
    "def normalization(image):\n",
    "    image = image / image.max()\n",
    "    return image\n",
    "\n",
    "\n",
    "training_path = \"./02_face_training\"\n",
    "test_path = './02_face_test'\n",
    "\n",
    "train_data, train_label = create_dataset_train(training_path)\n",
    "test_data, _ = create_dataset_test(test_path)\n",
    "\n",
    "train_data = normalization(train_data)\n",
    "test_data = normalization(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing test_result_DataFrame\n",
    "\n",
    "test_index = os.listdir(test_path)\n",
    "temp = []\n",
    "\n",
    "for index in test_index:\n",
    "    index = index.split(\".\")\n",
    "    temp.append(int(index[0]))\n",
    "    \n",
    "test_index = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train images : (1050, 56, 46)\n",
      "Shape of Train labels :  (1050,)\n",
      "Shape of Test images :  (700, 56, 46)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Train images :',train_data.shape)\n",
    "print('Shape of Train labels : ', train_label.shape)\n",
    "print('Shape of Test images : ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 2576)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               659712    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 351)               90207     \n",
      "=================================================================\n",
      "Total params: 749,919\n",
      "Trainable params: 749,919\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(56, 46)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(351, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "33/33 [==============================] - 1s 7ms/step - loss: 5.9728 - accuracy: 9.5238e-04\n",
      "Epoch 2/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.8030 - accuracy: 0.0038\n",
      "Epoch 3/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.6706 - accuracy: 0.0067\n",
      "Epoch 4/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.4511 - accuracy: 0.0057\n",
      "Epoch 5/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.1892 - accuracy: 0.0200\n",
      "Epoch 6/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.9046 - accuracy: 0.0371\n",
      "Epoch 7/40\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 4.5669 - accuracy: 0.0629\n",
      "Epoch 8/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.2288 - accuracy: 0.0876\n",
      "Epoch 9/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.9258 - accuracy: 0.1105\n",
      "Epoch 10/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.6517 - accuracy: 0.1514\n",
      "Epoch 11/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.3682 - accuracy: 0.1952\n",
      "Epoch 12/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.1464 - accuracy: 0.2371\n",
      "Epoch 13/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9206 - accuracy: 0.2933\n",
      "Epoch 14/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.6987 - accuracy: 0.3448\n",
      "Epoch 15/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.4935 - accuracy: 0.3838\n",
      "Epoch 16/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.3205 - accuracy: 0.4448\n",
      "Epoch 17/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.1685 - accuracy: 0.4790\n",
      "Epoch 18/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.0356 - accuracy: 0.4800\n",
      "Epoch 19/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.8870 - accuracy: 0.5486\n",
      "Epoch 20/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.7452 - accuracy: 0.5943\n",
      "Epoch 21/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.6715 - accuracy: 0.6000\n",
      "Epoch 22/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.5802 - accuracy: 0.6286\n",
      "Epoch 23/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.4820 - accuracy: 0.6610: 0s - loss: 1.4908 - accuracy: 0.65\n",
      "Epoch 24/40\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 1.3930 - accuracy: 0.6781\n",
      "Epoch 25/40\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 1.3359 - accuracy: 0.6962\n",
      "Epoch 26/40\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 1.2645 - accuracy: 0.7229\n",
      "Epoch 27/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.2192 - accuracy: 0.7181\n",
      "Epoch 28/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.1697 - accuracy: 0.7457\n",
      "Epoch 29/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.1108 - accuracy: 0.7390\n",
      "Epoch 30/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0335 - accuracy: 0.7790\n",
      "Epoch 31/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0040 - accuracy: 0.7771\n",
      "Epoch 32/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.9510 - accuracy: 0.8038\n",
      "Epoch 33/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.9326 - accuracy: 0.7971\n",
      "Epoch 34/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.8695 - accuracy: 0.8181\n",
      "Epoch 35/40\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.8420 - accuracy: 0.8295\n",
      "Epoch 36/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.7908 - accuracy: 0.8429\n",
      "Epoch 37/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.7795 - accuracy: 0.8362\n",
      "Epoch 38/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.7442 - accuracy: 0.8429\n",
      "Epoch 39/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.7232 - accuracy: 0.8419\n",
      "Epoch 40/40\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb5c90ce80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_label, epochs = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 351)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = []\n",
    "for image in predictions:\n",
    "    predict_label.append(np.argmax(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = np.array(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9019047619047619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(original, prediction):\n",
    "    accuracy = original == prediction\n",
    "    accuracy = np.count_nonzero(accuracy)\n",
    "    \n",
    "    return accuracy / original.shape[0]\n",
    "    \n",
    "accuracy(train_label, predict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 351)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "for image in predictions:\n",
    "    test_label.append(np.argmax(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 41 153 268 231 245  51 326 212  51 273 267 299 211  34  55 227 251 289\n",
      " 324  34 212 194 280 266 231  25 201 319 136 271 211 220 278 158 216 287\n",
      " 180 225 263 206 119 210 310 337 123 177 344 168 241 347 239 211 164 186\n",
      " 109 226 162  34 128 222  61 192 285 220 231 154 202 128 211 344 111 310\n",
      " 152 195 220 308 209 100  56 299 308 268 268 144 290 224 201 123 284 225\n",
      " 118 270 254 240 137 276 236 101 200 103 151 347 169 345  93 116 225 347\n",
      " 328 167 203 261 220 217 288 294 278 218 196 226 226 328 231 211 268 281\n",
      " 276 201 210 301 215 238 151 188 151 179 248 231 236 220  11 278 212 195\n",
      " 234 178 152 310  73 231 234  65 212  92 118 242 226 333  33 215 328  84\n",
      " 274 264 220 328 152 192 117 202 183 162 183 211   3 329 227 316 317 236\n",
      " 283 339 300  65 226 109 218 211 154 216 223  76 225 229 262 243 215 190\n",
      " 209 263 234 313 231 328 285 324 305 119  85 258 104  20 167 100  34 220\n",
      " 271 215 348 338 119 250 180 250 345 252 280 161 295 119 263 220  56 219\n",
      " 175 248 184 225 284 151 330 341 210 308 234 315 172 334 215 314 238 156\n",
      "  48 300 184 273  84 182 234 154 323 175 312 303 345 261 236 289 328 344\n",
      " 215 205 349  34 113 209 164 317 264  33 303 218  26 321 307 130 301 232\n",
      " 239 328 238 349  30 100 209  88 238 298 163 321 121 195  56  92 220  85\n",
      " 294 312 215 305 152  30 328 225 109 236 109 278 129 157 216 300 168 223\n",
      " 289 204 200 305 197 325 238 328 317 238 234 210 241 347 186 229 178 268\n",
      "  41 283 315 240 328 211 153 269 239 310 332 238 236 163 179 176 229 118\n",
      " 230  85 226 119 151 278 217 333 297 186 297 328 334 340  96 304 261 315\n",
      " 275 232 151 225 260 150 303 245  64 263 215 304 283  65 245 209  34 219\n",
      " 289 310 245 325  73  76 267 327 333 159 242 220 262 192 336 246 262 119\n",
      " 307 238 278 219 300  76  37 159  92 192 259 284 239 272 305 273 324 152\n",
      " 212 218 346 239 300 264 248 328 176 232 295 238 329 261 312 322 106 235\n",
      " 114 263 127 239 207 146  46 172 220 256 333 247 220 211 328 345 266 109\n",
      " 257 224 248 230 229  96 100 287 250 211 347 309 123 286 331 258 176  63\n",
      " 184 171 216 172  87 111 161 281 345 269 229 195 300 211 107 261 292 315\n",
      " 209  85 308 152 176  12 272  81 215 240 183 277 126 110 318 277 268 342\n",
      " 163  61 154 196 215 238 330 144 229 158 325 276 250 183 209 220 229 204\n",
      "  34 100 300 231 222 322 259 278 255 158 212 329 288 192  92 256 225 241\n",
      " 156 158  27 268 307 242 314 185 341 328 287 184 117 289 166 278 165 201\n",
      " 149 239 347 189  30 154 299 303  65 229 178 238 205  65 106 218 263 181\n",
      " 338 212 283 244 211 201  67 342 298 100 266 192 275 305 183 152 269 264\n",
      " 154 313 239 204 222 218 303 266 329  63  87 321 152 225 306 303 343 166\n",
      "  73 201 225 332 220 238 308  82 226 111 342 196 169 289 173 218 266  16\n",
      " 215 276 336  30 299 195 240 240 267 136 110 215 100 222 263 195  92 229\n",
      " 345 258 247 339 185 300 345 186 334 103 149 123 278 231 210  91 284 255\n",
      " 231 314 152 307 211 224 309 220 157 273 128 303 220 152 177 229]\n"
     ]
    }
   ],
   "source": [
    "#결과\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_df = pd.DataFrame([x for x in zip(test_index, test_label)], columns=['Image', 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image  Answer\n",
       "0      1      41\n",
       "1     10     153\n",
       "2    100     268\n",
       "3    101     231\n",
       "4    102     245"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>5</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image  Answer\n",
       "0        1      41\n",
       "111      2     261\n",
       "222      3     180\n",
       "333      4     238\n",
       "444      5     329"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_df = test_result_df.sort_values(by=\"Image\")\n",
    "test_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './result.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-38b5a8ec1431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_result_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./result.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kshje\\desktop\\ewha\\21-1\\생체인증보안\\workspace\\study_machine-learning\\assignment3_얼굴 인식\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kshje\\desktop\\ewha\\21-1\\생체인증보안\\workspace\\study_machine-learning\\assignment3_얼굴 인식\\venv\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kshje\\desktop\\ewha\\21-1\\생체인증보안\\workspace\\study_machine-learning\\assignment3_얼굴 인식\\venv\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kshje\\desktop\\ewha\\21-1\\생체인증보안\\workspace\\study_machine-learning\\assignment3_얼굴 인식\\venv\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './result.csv'"
     ]
    }
   ],
   "source": [
    "test_result_df.to_csv(\"./result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
